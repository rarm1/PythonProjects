# -*- coding: utf-8 -*-
"""
Created on Wed Aug 24 08:30:44 2022

@author: DKon1
"""
import optimisation_lib as edhec
import pandas
import pandas as pd
import scipy as sc
import numpy as np
from numpy import ndarray

"""
Video with the Thai Gentleman referred to after here. https://www.youtube.com/watch?v=gN3WIx6DYfw&ab_channel=PyConThailand
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Probably does not need to be changed
"""

# Globals / bound definitions.
df = pd.read_excel("Optimiser Data 9 Funds.xlsx", sheet_name='Sheet1', index_col=0)
gv_scores = df.iloc[[0]]
df.drop(df.index[[0]], inplace=True, axis=0)
df.dropna(axis=1, how='any', inplace=True)
df = df.astype(float)
df = df / 100
lower_bound_threshold = round(df.min().min(), 2)
upper_bound_threshold = round(df.max().max(), 2)
thresholds = np.arange(lower_bound_threshold, upper_bound_threshold, 0.01)
ann_rets = edhec.annualise_rets(df, 52)
covmat = df.cov()
# There is some preprocessing that goes in within some dataframes which make it difficult to calculate exactly what
# is going on and how to replicate it. Such as with the Thai Gentleman. He appears to just draw certain rows from the
# DF without talking about what they are or where they're generated.

# CONTS
RFR = 0.01
SHARPE = edhec.sharpe_ratio(df, RFR, 52)

"""
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
"""


def get_sharpe_ratio(weights: list, cov_mat: pandas.DataFrame) -> float:
    """
    This function takes dataframes and returns the sharpe ratio
    :param weights:
    :param cov_mat:
    :return:
    """
    port_ret = edhec.portfolio_return(weights, ann_rets)
    port_vol = edhec.portfolio_vol(weights, cov_mat)
    return port_ret / port_vol


def get_metrics(weights: list, cov_mat: pandas.DataFrame) -> float:
    """
    Calculates metrics. This is currently used for Sharpe Ratio exclusively.
    :param weights: this list is generated by the optimiser. It may not technically be a list, it could be a numpy
    array. Which functions in a similiar way.
    :param cov_mat: This is the covariance matrix. This is the covar between all assets.
    :return: Returns a float value. Multiplied by minus one because scipy can only optimise.
    """
    return get_sharpe_ratio(weights, cov_mat) * -1  # Because scipy only minimises what we're optimising.


def weightings_contraint(weights: list) -> float:
    # TODO: Could this function just return np.sum(weights)-1?
    if np.sum(weights) - 1 == 0:  # If the sum of float value minus one is 0 then we're at a 'full' portfolio.
        return 0.0  # What equality functions target is 0. Therefore, 0 is the success in this case. It is not bitwise
        # as I thought initially.
    else:
        return np.sum(weights) - 1  # This returns so the program knows how far off from goal weights we are.


def growth_value_contraint(weights: list) -> np.ndarray:
    return np.dot(weights, gv_scores.T)


def optimise(target_gvs):
    lb, ub = 0.00, 1.00
    first_weights: ndarray = np.repeat(1 / df.shape[1], df.shape[1])
    weighting_bounds = [(lb, ub) for _ in np.repeat(1 / df.shape[1], df.shape[1])]

    bnds = weighting_bounds
    weight_cons = {'type': 'eq', 'fun': weightings_contraint}
    gv_cons = {'type': 'eq', 'fun': lambda weights: target_gvs - growth_value_contraint(weights)}
    cons = [weight_cons, gv_cons]
    results = sc.optimize.minimize(get_metrics,
                                   x0=first_weights,
                                   args=covmat,
                                   method="SLSQP",
                                   bounds=bnds,
                                   constraints=cons,  # this lists as an error, it is not clear to me why.
                                   options={'disp': True}
                                   )

    return results


# Output modelling
# print(f"Time per execution: {timeit(optimise, number=10)}")
# optimised_weights = optimise()
output_arr = optimise(160.00)
print(output_arr)
# optimised_weights = [individual_calc.x for individual_calc in output_arr]
# optimised_weights_index = [[weighting, df.columns[index]] for index, weighting in enumerate(
#     optimised_weights)]
# print(sorted(optimised_weights_index, reverse=True))
# print([print(value) for value in sorted(optimised_weights_index, reverse=True)])
# print(str(round(weight, 2)*100) + "%") for weight in optimised_weights if weight > 0
# port_ret = edhec.portfolio_return(optimised_weights, ann_rets)
# port_vol = edhec.portfolio_vol(optimised_weights, covmat)
# print(f"Sharpe Ratio: {port_ret / port_vol}")


"""
SO articles: 
https://stackoverflow.com/questions/47443122/pythons-scipy-optimize-minimize-with-slsqp-fails-with-positive-directional-der
https://stackoverflow.com/questions/41137092/jacobian-and-hessian-inputs-in-scipy-optimize-minimize
https://stackoverflow.com/questions/50774022/how-to-set-bounds-when-minimizing-using-scipy  I like the potential of this one. 
    The concept this generates is an interesting one, could we have one minimise function that's express purpose 
    would be to generate portfolios that give us weightings within funds that generate a desirable growth value score THEN
    we generate a second function to rank order these weightings? I haven't seen (I don't think) a method that 
    Generates results in the same way that we're looking to with boundaries. 
"""

"""
Explanation of output.
fun: Value of the objective function
jac: Jacobian value of objective function
message: Exit message.
nfev: Number of evalations of the objective function
nit: Number of iterations performed by optimiser
njev: number of it's Jacobian evaluations
status: exit code. https://github.com/scipy/scipy/blob/main/scipy/optimize/slsqp/slsqp_optmz.f#L117 - line 115.
success: boolean: Whether exec was a success
x:   solution of the optimisation
"""

'''
Thai PhD approach:
Start with minimise.
Define hard contstraints - equation constraint (that's not what it means) np.dot the weights minus
    one should == 0.
Hard bound is each weight must be between 0,1 for range in the amount of vehicles used.
Then the quadratic form function is defined relatively simply as the matrix of covariance multiplied by
    the vector
of weights.
Constraints are then generated as hard constraints which is the eq - defined above
And then an ineq with the function being passed being a lambda function defined as matrix multiply vReturn and
weights - the threshold.
vreturn is just a column from his table, but at a guess I could just do mean return * amount returns.
Thresholders are defined as the following:
    np.arange, Lower, Upperbound, step=0.01
Lower = round(vReturn.min(), 2)
upper = round(vReturn.max(), 2)
'''
